<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="IndustRoPose: a real-time, zero-shot 6D pose tracker for industrial robotic manipulation, integrating SAM2 and MegaPose.">
  <meta name="keywords" content="IndustRoPose, 6D Pose Estimation, Robotic Manipulation, Zero-Shot, Real-Time Tracking, SAM2, MegaPose">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>IndustRoPose: Zero Shot Real-Time 6D Pose Tracking for Industrial Robotic Manipulation</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg">  -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">IndustRoPose: Zero Shot Real-Time 6D Pose Tracking for Industrial Robotic Manipulation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Sher Hazan ,</span>
            <span class="author-block">Nimrod Curtis ,</span>
            <span class="author-block">Anton Agafonov ,</span>
            <span class="author-block">Zohar Feldman ,</span>
            <span class="author-block">Dotan Di Castro </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"> Bosch Corporate Research, Haifa, Israel</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://sherhazan.github.io/IndustRoPose/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/YOUR_ARXIV_ID"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=YOUR_YOUTUBE_ID"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/imvc_teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        IndustRoPose enables robust, real-time 6D pose tracking for industrial assembly tasks like insertion and screwing.
      </h2>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Robotic assembly remains a core challenge in industrial automation, requiring high precision, real-time feedback, and adaptability across diverse parts and dynamic environments. While recent advances in 6D object pose estimation and foundation models offer promising capabilities, most approaches are evaluated in static environments and lack robust integration into industrial workflows. In this work, we introduce IndustRoPose, a real-time, zero-shot 6D pose tracker for industrial robotic manipulation. IndustRoPose integrates SAM2 for high-frequency segmentation with MegaPose for render-and-compare 6D pose estimation. Its mask-consistency scoring adaptively switches between tracking, refinement, and recovery modes, ensuring robustness under occlusion, motion blur, and visual ambiguity. IndustRoPose enables fast and easy onboarding of new objects using only a CAD model and a single annotated image, without task-specific retraining or simulation. We integrate IndustRoPose into the robot via a pose-based control policy that fuses perception with motion commands, maintaining stable tracking even during high-speed movements. To address flexible and scalable automation, we present IndustRobot, a modular framework for industrial robotic assembly. IndustRobot seamlessly integrates IndustRoPose with a skill-based manipulation layer, supporting adaptive behaviors and rapid task reconfiguration. This enables precise execution of contact-rich skills such as insertion, screwing, and part manipulation, while allowing skills to be reused or extended for new tasks with minimal programming. Finally, we demonstrate sub-millimeter pose accuracy and high task success rates, 96.7% for plug insertion and 97.5% for screwing, on real industrial assembly tasks, validating the practicality and robustness of the approach in dynamic environments.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/YOUR_YOUTUBE_ID_HERE?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method: IndustRoPose 6D Pose Tracker</h2>
        <div class="content has-text-justified">
        <p>
          At the core of our system is IndustRoPose, a real-time 6D pose tracking pipeline designed for robust performance on streaming RGB input. It integrates the rapid zero-shot segmentation capability of SAM2 with the precise render-and-compare estimation of MegaPose.
        </p>
        <p>
          <strong>How it works:</strong>
        </p>
        <ul>
          <li>
            <strong>Initialization:</strong> Before the stream begins, we initialize the system. SAM2 is given a pre-captured image and prompt points to automatically identify the target object. Simultaneously, MegaPose is loaded with the object's CAD model and camera intrinsic parameters.
          </li>
          <li>
            <strong>Tracking & Scoring:</strong> Once initialized, the system enters its tracking loop. At each timestep, it compares the current segmentation mask from SAM2 (the "ground truth") to a rendered mask from the previous pose estimate. We compute a "mask-consistency score" based on precision and recall to infer the tracking quality without running the expensive full pose estimation model every frame.
          </li>
          <li>
            <strong>Adaptive Modes:</strong> This score dynamically triggers one of three modes:
            <ol>
              <li><strong>Track:</strong> If the score is high, we assume the previous pose is accurate and carry it forward.</li>
              <li><strong>Refine:</strong> If the score is moderate (indicating minor drift), we trigger only the MegaPose refiner for a lightweight correction.</li>
              <li><strong>Recover:</strong> If the score is low (due to occlusion or fast motion), we re-run the full coarse-to-fine estimation process to re-acquire the pose.</li>
            </ol>
          </li>
        </ul>
        <p>
          This adaptive strategy balances accuracy and computational efficiency, ensuring real-time performance (over 10 FPS) even under challenging conditions like occlusion, motion blur, or partial object visibility.
        </p>
        </div>
        <img src="./static/images/Real-Time6DPoseTracker.png" alt="IndustRoPose pipeline architecture" style="width: 100%;"/>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">IndustRobot: Modular Skill-Based Manipulation</h2>
        <div class="content has-text-justified">
          <p>
            Illustration of the modular, skill-based manipulation for USB A assembly. The task is decomposed into a sequence of adaptive robot skills: Move to Object (approach and align for grasp), Move Gripper (grasping action), Move Robot (repositioning with object in hand), Move Object to (transport and align the object to target location), and Insertion (precise, contact-rich insertion). The insets highlight the object's perspective and gripper action at each stage.
          </p>
        </div>
        <img src="./static/images/PoseBasedRoboticManipulation.png" alt="Modular manipulation skills pipeline" style="width: 100%;"/>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Transformer-based Insertion Policy</h2>
        <div class="content has-text-justified">
          <p>
            Architecture of the transformer-based policy for precision insertion. Dual ResNet18 encoders extract 2D feature maps from multi-camera inputs. The concatenated features, augmented with positional encoding, are processed by a Transformer Encoder to find cross-view correspondences. Finally, an MLP decoder regresses the 6-DOF pose correction required for alignment.
          </p>
        </div>
        <img src="./static/images/transformer.png" alt="Transformer insertion policy architecture" style="width: 100%;"/>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Experimental Results</h2>
        <div class="content has-text-justified">
          <p>
            We evaluated our framework on two real-world tasks: plug insertion and screw driving, using a diverse set of standard industrial and consumer components.
          </p>
        </div>
        
        <h3 class="title is-4">Test Cases</h3>
        <img src="./static/images/text_cases.png" alt="Connectors and screws used in experiments" style="width: 100%;"/>
        <p class="has-text-centered">The set of connectors (USB, RJ45, HDMI) and screws (Hex, Phillips) used in our experiments.</p>
        <br>

        <h3 class="title is-4">Experimental Setup</h3>
        <img src="./static/images/setup.png" alt="Experimental setup with UR5e robot" style="width: 100%;"/>
        <p class="has-text-centered">Experimental setups for Plug Insertion (left) and Screw/Unscrew (right) using a UR5e arm, dual RealSense cameras, and task-specific end-effectors.</p>
        <br>

        <h3 class="title is-4">Success Rates</h3>
        <div class="content has-text-justified">
          <p>
            We achieved high success rates across all stages. For plug assembly, the full pipeline success rate was <b>96.67%</b>. For the screwing task, the full pipeline success rate was <b>97.50%</b>, validating the robustness and modularity of our approach.
          </p>
        </div>
        <div style="display: flex; justify-content: space-around; flex-wrap: wrap;">
          <img src="./static/images/table_1.png" alt="Plug assembly success rates" style="max-width: 48%; margin-bottom: 10px;"/>
          <img src="./static/images/table_2.png" alt="Screw/Unscrew success rates" style="max-width: 48%; margin-bottom: 10px;"/>
        </div>

      </div>
    </div>
    </div>
</section>
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{hazan2025industropose,
  title={IndustRoPose: Zero Shot Real-Time 6D Pose Tracking for Industrial Robotic Manipulation},
  author={Hazan, Sher and Curtis, Nimrod and Agafonov, Anton and Feldman, Zohar and Di Castro, Dotan},
  booktitle={Proceedings of the ... (e.g., IEEE International Conference on Robotics and Automation (ICRA))},
  year={2025}
}</code></pre>
  </div>
</section>
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website borrowed from <a href="https://nerfies.github.io/">NeRFies</a> under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
        </div>
    </div>
  </div>
</footer>

</body>
</html>